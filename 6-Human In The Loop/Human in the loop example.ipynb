{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8cff6051-a6f7-4dc0-9230-860eb3ada271",
   "metadata": {},
   "source": [
    "# Mathematical Agent with Human in the Loop\n",
    "\n",
    "In this example, we'll see how to create a mathematical agent with human-in-the-loop functionality for factorial and Fibonacci calculations. The agent will ask for user confirmation **only when computing large values**:\n",
    "- Factorial: n > 170\n",
    "- Fibonacci: n > 1000\n",
    "\n",
    "This demonstrates how to use LangGraph's interrupt mechanism to conditionally pause execution and wait for user approval before proceeding with potentially resource-intensive operations.  \n",
    "This approval could be used for example when the model want to access a specific web resource and it pause the excecution until the human tells that can continue or you want to consider a more complex workflow for example before let the agent respond to a client request check that is ok before sending an email."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d486337d-c6eb-40ac-9552-ef5ab71a6146",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install langchain-openai==1.1.0\n",
    "# !pip install langchain==1.1.0\n",
    "# !pip install langgraph==1.0.4\n",
    "# !pip install python-dotenv==1.2.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "48155bc4-1544-49e4-99aa-926d039a5628",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langgraph.graph import StateGraph, END\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.types import Command\n",
    "from langchain_openai import ChatOpenAI\n",
    "from dotenv import load_dotenv\n",
    "from langchain_core.messages import AIMessage, HumanMessage, ToolMessage, SystemMessage\n",
    "from langgraph.types import interrupt\n",
    "from langgraph.graph import MessagesState\n",
    "import os\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6abd2345-3bb9-41bd-aedc-4423e54b609b",
   "metadata": {},
   "source": [
    "## 3. Configure API Key\n",
    "\n",
    "Set up the OpenAI API key. Make sure you have your API key in a `.env` file or set it directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a2951560-33fb-40fe-b979-60c2ef6fd6aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ OpenAI API key loaded successfully\n"
     ]
    }
   ],
   "source": [
    "# Set the OpenAI API key from environment variable\n",
    "# Make sure you have OPENAI_API_KEY in your .env file or uncomment the line below\n",
    "# os.environ['OPENAI_API_KEY'] = 'your-api-key-here'\n",
    "\n",
    "api_key = os.getenv('OPENAI_API_KEY')\n",
    "if not api_key:\n",
    "    print(\"âš ï¸ Warning: OPENAI_API_KEY not found in environment variables\")\n",
    "else:\n",
    "    print(\"âœ“ OpenAI API key loaded successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74caef4d-629a-4599-b0a7-8f78b77d8a94",
   "metadata": {},
   "source": [
    "## Tool Definitions\n",
    "\n",
    "We define two mathematical computation tools: `compute_factorial` and `compute_fibonacci`.   \n",
    "These are similar to the one used in previous tutorial but are removed the if condition in computation for big numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6e482c10-beba-4a52-8542-7bce1dd0a4f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Mathematical tools defined successfully\n"
     ]
    }
   ],
   "source": [
    "def compute_factorial(n: int) -> dict:\n",
    "    \"\"\"Calculates the factorial of a non-negative integer.\n",
    "    \n",
    "    Args:\n",
    "        n (int): The non-negative integer to compute factorial for\n",
    "        \n",
    "    Returns:\n",
    "        dict: Computation status and result\n",
    "    \"\"\"\n",
    "    print(f\"ðŸ”§ TOOL CALLED: compute_factorial\")\n",
    "    print(f\"   INPUT: n = {n}\")\n",
    "    \n",
    "    if n < 0:\n",
    "        result = {\"status\": \"error\", \"error_message\": \"Factorial is not defined for negative numbers.\"}\n",
    "        print(f\"   OUTPUT: {result}\")\n",
    "        return result\n",
    "    \n",
    "    try:\n",
    "        factorial_result = 1\n",
    "        for i in range(2, n + 1):\n",
    "            factorial_result *= i\n",
    "        \n",
    "        result = {\"status\": \"success\", \"result\": f\"The factorial of {n} is {factorial_result}\"}\n",
    "        print(f\"   OUTPUT: {result}\")\n",
    "        return result\n",
    "    except Exception as e:\n",
    "        result = {\"status\": \"error\", \"error_message\": f\"Error computing factorial: {str(e)}\"}\n",
    "        print(f\"   OUTPUT: {result}\")\n",
    "        return result\n",
    "\n",
    "def compute_fibonacci(n: int) -> dict:\n",
    "    \"\"\"Calculates the nth Fibonacci number (0-indexed).\n",
    "    \n",
    "    Args:\n",
    "        n (int): The position in the Fibonacci sequence (0-indexed)\n",
    "        \n",
    "    Returns:\n",
    "        dict: Computation status and result\n",
    "    \"\"\"\n",
    "    print(f\"ðŸ”§ TOOL CALLED: compute_fibonacci\")\n",
    "    print(f\"   INPUT: n = {n}\")\n",
    "    \n",
    "    if n < 0:\n",
    "        result = {\"status\": \"error\", \"error_message\": \"Fibonacci is not defined for negative positions.\"}\n",
    "        print(f\"   OUTPUT: {result}\")\n",
    "        return result\n",
    "    \n",
    "    try:\n",
    "        if n == 0:\n",
    "            fib_result = 0\n",
    "        elif n == 1:\n",
    "            fib_result = 1\n",
    "        else:\n",
    "            a, b = 0, 1\n",
    "            for _ in range(2, n + 1):\n",
    "                a, b = b, a + b\n",
    "            fib_result = b\n",
    "        \n",
    "        result = {\"status\": \"success\", \"result\": f\"The {n}th Fibonacci number is {fib_result}\"}\n",
    "        print(f\"   OUTPUT: {result}\")\n",
    "        return result\n",
    "    except Exception as e:\n",
    "        result = {\"status\": \"error\", \"error_message\": f\"Error computing Fibonacci: {str(e)}\"}\n",
    "        print(f\"   OUTPUT: {result}\")\n",
    "        return result\n",
    "\n",
    "print(\"âœ“ Mathematical tools defined successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfefbe13-d12f-424e-8bfb-037e3dfe018a",
   "metadata": {},
   "source": [
    "## State Definition\n",
    "\n",
    "The application state is kept minimal and tracks only what we need:\n",
    "- **`user_approved`**: Boolean flag indicating whether the user approved a tool execution\n",
    "\n",
    "In this example we use also MessagesState class that stores that is a class that stores 'messages' variable and is provided by langgraph  message."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ba184923-ca75-42d2-8047-f768fc0f8025",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class State(MessagesState):\n",
    "    user_approved: bool"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "951b672a-ceec-48e2-a923-0ba9d65c7135",
   "metadata": {},
   "source": [
    "## LLM Configuration\n",
    "\n",
    "We configure the LLM with tool binding using `bind_tools()` to make mathematical tools available.\n",
    "\n",
    "**Important**: We use `bind_tools()` instead of `create_agent()` because we want manual control over tool execution (for human approval).\n",
    "To understand better be sure to check also the previous example of this series where we expained how the Agentic tool calling flow works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5b4fe7eb-adb1-4671-ab91-a97deaaef79d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Math agent configured with factorial and Fibonacci tools\n",
      "âœ“ System message defined for better agent behavior\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import SystemMessage\n",
    "\n",
    "math_llm = ChatOpenAI(model=\"gpt-5-mini\", temperature=0)\n",
    "\n",
    "# Factorial and Fibonacci tools\n",
    "math_tools = [compute_factorial, compute_fibonacci]\n",
    "\n",
    "# System message to guide agent behavior\n",
    "system_message = SystemMessage(content=\"\"\"You are a mathematical computation specialist. \n",
    "You can calculate factorial and Fibonacci numbers. \n",
    "When the user asks for computations, use the appropriate tool:\n",
    "- For factorial calculations, use `compute_factorial`\n",
    "- For Fibonacci sequence numbers, use `compute_fibonacci`\n",
    "\"\"\")\n",
    "\n",
    "# Bind tools to LLM\n",
    "llm_with_tools = math_llm.bind_tools(math_tools)\n",
    "\n",
    "print(\"âœ“ Math agent configured with factorial and Fibonacci tools\")\n",
    "print(\"âœ“ System message defined for better agent behavior\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efb38155-90fc-45d3-bd5a-8722ce26327d",
   "metadata": {},
   "source": [
    "## Agent Node\n",
    "\n",
    "This agent node calls the LLM to determine what action to take.  \n",
    "This node does NOT execute tools automatically. It only generates the tool call request, which will then go through the approval process.  \n",
    "As you can see there is the invocation without iteration. In our cause this is crucial because we have to add a confirmation step after the first invocation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bef34513-d470-468b-ba9d-0acd045f032d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def agent_node(state: State):\n",
    "    messages = state[\"messages\"]\n",
    "\n",
    "    response = llm_with_tools.invoke(messages)\n",
    "\n",
    "    return {\"messages\": [response]}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d115233-c6fb-4a21-a218-8088720ab307",
   "metadata": {},
   "source": [
    "## Human Approval Node\n",
    "\n",
    "This is where incept the approval request! This node:\n",
    "1. Checks if the agent wants to call a tool\n",
    "2. Extracts the tool name and arguments\n",
    "3. Applies conditional logic based on the tool and input value:\n",
    "   - **Factorial with n > 170**: Requires human approval\n",
    "   - **Fibonacci with n > 1000**: Requires human approval\n",
    "   - **All other cases**: Auto-approves and continues\n",
    "\n",
    "When approval is needed the flow is paused with `interrupt()` and updates the state based on their response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d77e7745-4566-4284-9f68-9f7001b0ce59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Human approval node defined\n"
     ]
    }
   ],
   "source": [
    "def human_approval_node(state: State):\n",
    "    \"\"\"\n",
    "    Check if the last message has tool calls and request human approval based on conditions:\n",
    "    - Factorial: n > 170\n",
    "    - Fibonacci: n > 1000\n",
    "    \"\"\"\n",
    "    last_message = state[\"messages\"][-1]\n",
    "    \n",
    "    # Check if the last message is from AI and has tool calls\n",
    "    if isinstance(last_message, AIMessage) and last_message.tool_calls:\n",
    "        tool_call = last_message.tool_calls[0]\n",
    "        tool_name = tool_call[\"name\"]\n",
    "        tool_args = tool_call[\"args\"]\n",
    "        n_value = tool_args.get(\"n\", 0)\n",
    "        \n",
    "        # Determine if approval is needed based on tool and threshold\n",
    "        needs_approval = False\n",
    "        threshold_msg = \"\"\n",
    "        \n",
    "        if tool_name == \"compute_factorial\" and n_value > 170:\n",
    "            needs_approval = True\n",
    "            threshold_msg = \"n > 170\"\n",
    "        elif tool_name == \"compute_fibonacci\" and n_value > 1000:\n",
    "            needs_approval = True\n",
    "            threshold_msg = \"n > 1000\"\n",
    "        \n",
    "        if needs_approval:\n",
    "            print(f\"\\nAPPROVAL REQUIRED FOR LARGE COMPUTATION\")\n",
    "            print(f\"Tool: {tool_name}\")\n",
    "            print(f\"Arguments: {tool_args}\")\n",
    "            print(f\"This computation may be resource-intensive ({threshold_msg})\")\n",
    "            \n",
    "            approval = interrupt(f\"Do you want to proceed with {tool_name}(n={n_value})? \"\n",
    "                 f\"This is a large computation. Type 'yes' to approve or 'no' to cancel: \")\n",
    "            \n",
    "            if approval and approval.lower() in [\"yes\", \"y\"]:\n",
    "                print(\"User approved. Proceeding with computation...\")\n",
    "                return {\"user_approved\": True}\n",
    "            else:\n",
    "                print(\"User denied. Cancelling computation...\")\n",
    "                return {\"user_approved\": False}\n",
    "        else:\n",
    "            # Auto-approve for small values\n",
    "            print(f\"âœ“ Auto-approved: {tool_name}(n={n_value}) - within safe limits\")\n",
    "            return {\"user_approved\": True}\n",
    "    \n",
    "    return state\n",
    "\n",
    "print(\"âœ“ Human approval node defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "815ab076-fc3b-46c3-9880-637c1b65c5b1",
   "metadata": {},
   "source": [
    "## Conditional Edge Functions\n",
    "\n",
    "These functions control the workflow routing:\n",
    "\n",
    "### `should_continue()`\n",
    "After the agent responds, this function determines the next step:\n",
    "- If the agent wants to call a tool â†’ go to `human_approval`\n",
    "- Otherwise â†’ end the conversation\n",
    "\n",
    "### `after_approval()`\n",
    "After the human approval check, this function decides:\n",
    "- If approved (`user_approved == True`) â†’ execute the tool\n",
    "- If denied (`user_approved == False`) â†’ end without executing tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d89541ba-4fa9-484b-bbf0-d2953fb9ad83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def should_continue(state: State):\n",
    "    last_message = state[\"messages\"][-1]\n",
    "    if isinstance(last_message, AIMessage) and last_message.tool_calls:\n",
    "        return \"human_approval\"\n",
    "\n",
    "    return END\n",
    "\n",
    "def after_approval(state: State):\n",
    "    if state.get(\"user_approved\", False):\n",
    "        return \"tools\"\n",
    "    else:\n",
    "        return END"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b13f3698-b637-40dd-ad45-3a6d59afe095",
   "metadata": {},
   "source": [
    "## Graph Construction\n",
    "\n",
    "Now we build the complete workflow graph with the following structure:\n",
    "1. **Entry point**: User's question goes to the `agent` node\n",
    "2. **Conditional routing**: After agent response, we check if it wants to call a tool\n",
    "3. **Approval check**: If yes, go to `human_approval` to check thresholds and get user consent\n",
    "4. **Tool execution**: If approved, execute the tool and return to agent for final response\n",
    "5. **Loop closure**: After tool execution, return to agent to formulate the final answer\n",
    "\n",
    "The `MemorySaver` checkpointer maintains state, allowing the conversation to pause and resume."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9b96422e-10c6-4636-846a-43a4cc2926e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.prebuilt import ToolNode\n",
    "\n",
    "# Create tool node that will execute tools\n",
    "tool_node = ToolNode(math_tools)\n",
    "\n",
    "# Build the workflow\n",
    "workflow = StateGraph(State)\n",
    "\n",
    "# Add nodes\n",
    "workflow.add_node(\"agent\", agent_node)\n",
    "workflow.add_node(\"human_approval\", human_approval_node)\n",
    "workflow.add_node(\"tools\", tool_node)\n",
    "\n",
    "\n",
    "# Set up edges\n",
    "workflow.set_entry_point(\"agent\")\n",
    "workflow.add_conditional_edges(\"agent\", should_continue, [\"human_approval\", END])\n",
    "workflow.add_conditional_edges(\"human_approval\", after_approval, [\"tools\", END])\n",
    "workflow.add_edge(\"tools\", \"agent\")  # After tools execute, go back to agent to formulate response\n",
    "\n",
    "# Compile with checkpointer (memory) to manage human-in-the-loop\n",
    "memory = MemorySaver()\n",
    "graph = workflow.compile(checkpointer=memory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35626780-8778-4de8-85cc-b90a1d676f1a",
   "metadata": {},
   "source": [
    "## Visualize the Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "972f128f-e72e-49b9-bf5a-9fe680651000",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb77a4fd-ffcf-48cf-a421-b186c59140ca",
   "metadata": {},
   "source": [
    "## Wrong Usage Example\n",
    "\n",
    "This demonstrates an **incorrect** way to use the graph we have defined. We call `invoke()` directly, which doesn't properly handle the human-in-the-loop mechanism. While this seems to work for auto-approved cases (like factorial of 10), it bypasses the proper streaming flow needed for interrupts when needed.  \n",
    "We have to use `stream()` with proper interrupt handling.\n",
    "\n",
    "**Note**: If running the following cell multiple times, change the `thread_id` to avoid conflicts with the conversation memory getting unexpected errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ee618035-b7af-4f15-b75f-d66f46da6d03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "TEST 1: WRONG CODE: Small Factorial (n=10, auto-approved)\n",
      "============================================================\n",
      "âœ“ Auto-approved: compute_factorial(n=10) - within safe limits\n",
      "ðŸ”§ TOOL CALLED: compute_factorial\n",
      "   INPUT: n = 10\n",
      "   OUTPUT: {'status': 'success', 'result': 'The factorial of 10 is 3628800'}\n",
      "\n",
      "Final Answer: 10! = 3,628,800\n"
     ]
    }
   ],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "user_input = \"What is the factorial of 10?\"\n",
    "\n",
    "initial_state = {\n",
    "    \"messages\": [system_message, HumanMessage(content=user_input)]\n",
    "}\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"TEST 1: WRONG CODE: Small Factorial (n=10, auto-approved)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Execute the graph directly\n",
    "result = graph.invoke(initial_state, config)\n",
    "\n",
    "# Print the final response\n",
    "final_message = result[\"messages\"][-1]\n",
    "print(f\"\\nFinal Answer: {final_message.content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ee9e3b7",
   "metadata": {},
   "source": [
    "## Test: Fibonacci with Auto-Approval\n",
    "\n",
    "This test uses the **correct** approach with `stream()`. Computing the 50th Fibonacci number is well within the safe threshold (n â‰¤ 1000), so the workflow will automatically approve and execute without requiring user intervention.\n",
    "\n",
    "**Note**: Change the `thread_id` if running multiple times to avoid continuation of previous conversations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fd90195f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "TEST 2: Small Fibonacci (n=50, auto-approved)\n",
      "============================================================\n",
      "\n",
      "User asked: Calculate the 50th Fibonacci number\n",
      "\n",
      "Agent wants to call: compute_fibonacci(n=50)\n",
      "âœ“ Auto-approved: compute_fibonacci(n=50) - within safe limits\n",
      "\n",
      "Agent wants to call: compute_fibonacci(n=50)\n",
      "ðŸ”§ TOOL CALLED: compute_fibonacci\n",
      "   INPUT: n = 50\n",
      "   OUTPUT: {'status': 'success', 'result': 'The 50th Fibonacci number is 12586269025'}\n",
      "\n",
      "Tool Response: {\"status\": \"success\", \"result\": \"The 50th Fibonacci number is 12586269025\"}\n",
      "\n",
      "Agent response: F(50) = 12586269025\n"
     ]
    }
   ],
   "source": [
    "config_fib_small = {\"configurable\": {\"thread_id\": \"2\"}}\n",
    "\n",
    "user_input_fib = \"Calculate the 50th Fibonacci number\"\n",
    "\n",
    "initial_state_fib = {\n",
    "    \"messages\": [system_message, HumanMessage(content=user_input_fib)]\n",
    "}\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"TEST 2: Small Fibonacci (n=50, auto-approved)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# First execution - will hit the interrupt\n",
    "for event in graph.stream(initial_state_fib, config_fib_small, stream_mode=\"values\"):\n",
    "    if \"messages\" in event:\n",
    "        last_msg = event[\"messages\"][-1]\n",
    "\n",
    "        if isinstance(last_msg, HumanMessage) and last_msg.content:\n",
    "            print(f\"\\nUser asked: {last_msg.content}\")\n",
    "        if isinstance(last_msg, ToolMessage) and last_msg.content:\n",
    "            print(f\"\\nTool Response: {last_msg.content}\")\n",
    "        if isinstance(last_msg, AIMessage) and last_msg.tool_calls:\n",
    "            print(f\"\\nAgent wants to call: {last_msg.tool_calls[0]['name']}(n={last_msg.tool_calls[0]['args']['n']})\")\n",
    "        if isinstance(last_msg, AIMessage) and last_msg.content:\n",
    "            print(f\"\\nAgent response: {last_msg.content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a79537e",
   "metadata": {},
   "source": [
    "## Test: Large Factorial (n > 170)\n",
    "\n",
    "This test triggers the human-in-the-loop approval mechanism. Computing factorial of 200 exceeds the threshold (n > 170), so the graph will pause execution and request user confirmation before proceeding with the computation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7701d4e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "TEST 3: Large Factorial (n=200, requires approval)\n",
      "============================================================\n",
      "\n",
      "User asked: What is the factorial of 200?\n",
      "\n",
      "Agent wants to call: compute_factorial(n=200)\n",
      "\n",
      "APPROVAL REQUIRED FOR LARGE COMPUTATION\n",
      "Tool: compute_factorial\n",
      "Arguments: {'n': 200}\n",
      "This computation may be resource-intensive (n > 170)\n",
      "\n",
      "Agent wants to call: compute_factorial(n=200)\n"
     ]
    }
   ],
   "source": [
    "config_large_fact = {\"configurable\": {\"thread_id\": \"3\"}}\n",
    "\n",
    "user_input_large_fact = \"What is the factorial of 200?\"\n",
    "\n",
    "initial_state_large_fact = {\n",
    "    \"messages\": [system_message, HumanMessage(content=user_input_large_fact)]\n",
    "}\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"TEST 3: Large Factorial (n=200, requires approval)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for event in graph.stream(initial_state_large_fact, config_large_fact, stream_mode=\"values\"):\n",
    "    if \"messages\" in event:\n",
    "        last_msg = event[\"messages\"][-1]\n",
    "\n",
    "        if isinstance(last_msg, HumanMessage) and last_msg.content:\n",
    "            print(f\"\\nUser asked: {last_msg.content}\")\n",
    "        if isinstance(last_msg, ToolMessage) and last_msg.content:\n",
    "            print(f\"\\nTool Response: {last_msg.content}\")\n",
    "        if isinstance(last_msg, AIMessage) and last_msg.tool_calls:\n",
    "            print(f\"\\nAgent wants to call: {last_msg.tool_calls[0]['name']}(n={last_msg.tool_calls[0]['args']['n']})\")\n",
    "        if isinstance(last_msg, AIMessage) and last_msg.content:\n",
    "            print(f\"\\nAgent response: {last_msg.content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "193b4097-2251-475b-94c0-5d7bc5fa6c75",
   "metadata": {},
   "source": [
    "## Resume Execution After Approval\n",
    "\n",
    "After the graph interrupts and requests confirmation, we can resume execution by streaming with `Command(resume=\"yes\")`. This continues from the paused state and completes the computation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f541eab-0c15-413c-99b9-1588d65f105a",
   "metadata": {},
   "source": [
    "The graph is currently interrupted inside the `human_approval` node, waiting for user confirmation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b3f5c26c-ddcf-4f6e-9cbe-5a3b0797cc46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('human_approval',)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.get_state(config_large_fact).next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2dd5ca31-22e7-4b6d-bf9d-d0faab39263a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "APPROVAL REQUIRED FOR LARGE COMPUTATION\n",
      "Tool: compute_factorial\n",
      "Arguments: {'n': 200}\n",
      "This computation may be resource-intensive (n > 170)\n",
      "User approved. Proceeding with computation...\n",
      "ðŸ”§ TOOL CALLED: compute_factorial\n",
      "   INPUT: n = 200\n",
      "   OUTPUT: {'status': 'success', 'result': 'The factorial of 200 is 788657867364790503552363213932185062295135977687173263294742533244359449963403342920304284011984623904177212138919638830257642790242637105061926624952829931113462857270763317237396988943922445621451664240254033291864131227428294853277524242407573903240321257405579568660226031904170324062351700858796178922222789623703897374720000000000000000000000000000000000000000000000000'}\n",
      "\n",
      "Tool Response: {\"status\": \"success\", \"result\": \"The factorial of 200 is 788657867364790503552363213932185062295135977687173263294742533244359449963403342920304284011984623904177212138919638830257642790242637105061926624952829931113462857270763317237396988943922445621451664240254033291864131227428294853277524242407573903240321257405579568660226031904170324062351700858796178922222789623703897374720000000000000000000000000000000000000000000000000\"}\n",
      "\n",
      "Agent response: 788657867364790503552363213932185062295135977687173263294742533244359449963403342920304284011984623904177212138919638830257642790242637105061926624952829931113462857270763317237396988943922445621451664240254033291864131227428294853277524242407573903240321257405579568660226031904170324062351700858796178922222789623703897374720000000000000000000000000000000000000000000000000\n"
     ]
    }
   ],
   "source": [
    "for event in graph.stream(\n",
    "    Command(resume=\"yes\"),\n",
    "    config_large_fact,\n",
    "    stream_mode=\"values\",\n",
    "):\n",
    "    # print(event)\n",
    "    if \"messages\" in event:\n",
    "        last_msg = event[\"messages\"][-1]\n",
    "        \n",
    "        if isinstance(last_msg, ToolMessage) and last_msg.content:\n",
    "            print(f\"\\nTool Response: {last_msg.content}\")\n",
    "        if isinstance(last_msg, AIMessage) and last_msg.content:\n",
    "            print(f\"\\nAgent response: {last_msg.content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfd109e1-c062-422a-8ffc-bac5252500fc",
   "metadata": {},
   "source": [
    "## Test: Large Fibonacci (n > 1000)\n",
    "\n",
    "This test demonstrates the approval mechanism for Fibonacci calculations. Computing the 1500th Fibonacci number exceeds the threshold (n > 1000), triggering the human-in-the-loop approval process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dc842942",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "TEST 4: Large Fibonacci (n=1500, requires approval)\n",
      "============================================================\n",
      "\n",
      "User asked: What is the Fibonacci of 1500?\n",
      "\n",
      "Agent wants to call: compute_fibonacci(n=1500)\n",
      "\n",
      "APPROVAL REQUIRED FOR LARGE COMPUTATION\n",
      "Tool: compute_fibonacci\n",
      "Arguments: {'n': 1500}\n",
      "This computation may be resource-intensive (n > 1000)\n",
      "\n",
      "Agent wants to call: compute_fibonacci(n=1500)\n"
     ]
    }
   ],
   "source": [
    "config_large_fib = {\"configurable\": {\"thread_id\": \"4\"}}\n",
    "\n",
    "user_input_large_fib = \"What is the Fibonacci of 1500?\"\n",
    "\n",
    "initial_state_large_fib = {\n",
    "    \"messages\": [system_message, HumanMessage(content=user_input_large_fib)]\n",
    "}\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"TEST 4: Large Fibonacci (n=1500, requires approval)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# First execution - will hit the interrupt\n",
    "for event in graph.stream(initial_state_large_fib, config_large_fib, stream_mode=\"values\"):\n",
    "    if \"messages\" in event:\n",
    "        last_msg = event[\"messages\"][-1]\n",
    "        \n",
    "        if isinstance(last_msg, HumanMessage) and last_msg.content:\n",
    "            print(f\"\\nUser asked: {last_msg.content}\")\n",
    "        if isinstance(last_msg, ToolMessage) and last_msg.content:\n",
    "            print(f\"\\nTool Response: {last_msg.content}\")\n",
    "        if isinstance(last_msg, AIMessage) and last_msg.tool_calls:\n",
    "            print(f\"\\nAgent wants to call: {last_msg.tool_calls[0]['name']}(n={last_msg.tool_calls[0]['args']['n']})\")\n",
    "        if isinstance(last_msg, AIMessage) and last_msg.content:\n",
    "            print(f\"\\nAgent response: {last_msg.content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f64a2aa-fd67-4928-9e18-4b58decf318f",
   "metadata": {},
   "source": [
    "## Resume Fibonacci Computation\n",
    "\n",
    "Resume the paused Fibonacci computation by providing user approval:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aedf5bd-f21c-4de7-9770-ca0719ef7a88",
   "metadata": {},
   "source": [
    "The graph is currently interrupted inside the `human_approval` node, waiting for user confirmation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "507ab4e2-defb-4974-b747-f17529545970",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('human_approval',)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.get_state(config_large_fib).next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6739f47b-8ec8-47be-ab4f-a64701547ef4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "APPROVAL REQUIRED FOR LARGE COMPUTATION\n",
      "Tool: compute_fibonacci\n",
      "Arguments: {'n': 1500}\n",
      "This computation may be resource-intensive (n > 1000)\n",
      "User approved. Proceeding with computation...\n",
      "ðŸ”§ TOOL CALLED: compute_fibonacci\n",
      "   INPUT: n = 1500\n",
      "   OUTPUT: {'status': 'success', 'result': 'The 1500th Fibonacci number is 13551125668563101951636936867148408377786010712418497242133543153221487310873528750612259354035717265300373778814347320257699257082356550045349914102924249595997483982228699287527241931811325095099642447621242200209254439920196960465321438498305345893378932585393381539093549479296194800838145996187122583354898000'}\n",
      "\n",
      "Tool Response: {\"status\": \"success\", \"result\": \"The 1500th Fibonacci number is 13551125668563101951636936867148408377786010712418497242133543153221487310873528750612259354035717265300373778814347320257699257082356550045349914102924249595997483982228699287527241931811325095099642447621242200209254439920196960465321438498305345893378932585393381539093549479296194800838145996187122583354898000\"}\n",
      "\n",
      "Agent response: F_1500 (with F_0 = 0, F_1 = 1) is:\n",
      "\n",
      "13551125668563101951636936867148408377786010712418497242133543153221487310873528750612259354035717265300373778814347320257699257082356550045349914102924249595997483982228699287527241931811325095099642447621242200209254439920196960465321438498305345893378932585393381539093549479296194800838145996187122583354898000\n",
      "\n",
      "This number has 314 digits.\n"
     ]
    }
   ],
   "source": [
    "for event in graph.stream(\n",
    "    # highlight-next-line\n",
    "    Command(resume=\"yes\"),\n",
    "    config_large_fib,\n",
    "    stream_mode=\"values\",\n",
    "):\n",
    "    if \"messages\" in event:\n",
    "        last_msg = event[\"messages\"][-1]\n",
    "        \n",
    "        if isinstance(last_msg, ToolMessage) and last_msg.content:\n",
    "            print(f\"\\nTool Response: {last_msg.content}\")\n",
    "        if isinstance(last_msg, AIMessage) and last_msg.content:\n",
    "            print(f\"\\nAgent response: {last_msg.content}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bca312d-d45f-4593-8bc9-b744958f97f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
