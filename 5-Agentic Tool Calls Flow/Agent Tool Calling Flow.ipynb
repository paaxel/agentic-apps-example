{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d87e6b3-5b90-4910-ae52-c8e344aa9db3",
   "metadata": {},
   "source": [
    "# How Agent Tool Calling Flow Works\n",
    "\n",
    "## Overview\n",
    "In this example, we'll explore **how LLMs execute tool calls** at a low level. We'll manually implement the tool-calling flow that libraries like LangChain typically handle automatically.\n",
    "\n",
    "## Why Learn This?\n",
    "- **Understanding**: See what happens \"under the hood\" during tool calling\n",
    "- **Debugging**: Better troubleshoot issues in production systems\n",
    "\n",
    "## The Tool Calling Process\n",
    "When you bind tools to an LLM:\n",
    "1. **User Query** â†’ LLM receives the question\n",
    "2. **LLM Reasoning** â†’ Decides which tool(s) to call\n",
    "3. **Tool Call Request** â†’ LLM returns structured tool call instructions\n",
    "4. **Tool Execution** â†’ Your code executes the requested tools\n",
    "5. **Result Return** â†’ Tool outputs are sent back to LLM\n",
    "6. **Final Response** â†’ LLM generates a natural language answer\n",
    "\n",
    "In most libraries the **Tool Execution** and **Result Return** are executed in loop automaticcally. Here, we'll implement them manually for educational purposes to understand better the flow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "630a83ec-d93a-42fe-95c1-dd946fe85b20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langgraph.graph import StateGraph, END\n",
    "from langchain_openai import ChatOpenAI\n",
    "from typing import TypedDict, Literal\n",
    "import math\n",
    "from dotenv import load_dotenv\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "import os\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4b22357-22c6-400c-9822-176de7a976b0",
   "metadata": {},
   "source": [
    "## 3. Configure API Key\n",
    "\n",
    "Set up the OpenAI API key. Make sure you have your API key in a `.env` file or set it directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f56c1ebf-ea0e-440d-a59b-e364d54ba4d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ OpenAI API key loaded successfully\n"
     ]
    }
   ],
   "source": [
    "# Set the OpenAI API key from environment variable\n",
    "# Make sure you have OPENAI_API_KEY in your .env file or uncomment the line below\n",
    "# os.environ['OPENAI_API_KEY'] = 'your-api-key-here'\n",
    "\n",
    "api_key = os.getenv('OPENAI_API_KEY')\n",
    "if not api_key:\n",
    "    print(\"âš ï¸ Warning: OPENAI_API_KEY not found in environment variables\")\n",
    "else:\n",
    "    print(\"âœ“ OpenAI API key loaded successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dc4a7de-3c2e-4f45-b74f-1e8a5f4dbbe8",
   "metadata": {},
   "source": [
    "## Tool Definitions\n",
    "\n",
    "Let's define some tools that can be used by our LLM.  \n",
    "These are the standard mathematical tools we've used in previous examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b01f2614-952b-4841-993f-d17511d08edc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Mathematical tools defined successfully\n"
     ]
    }
   ],
   "source": [
    "def compute_factorial(n: int) -> dict:\n",
    "    \"\"\"Calculates the factorial of a non-negative integer.\n",
    "    \n",
    "    Args:\n",
    "        n (int): The non-negative integer to compute factorial for\n",
    "        \n",
    "    Returns:\n",
    "        dict: Computation status and result\n",
    "    \"\"\"\n",
    "    print(f\"ðŸ”§ TOOL CALLED: compute_factorial\")\n",
    "    print(f\"   INPUT: n = {n}\")\n",
    "    \n",
    "    if n < 0:\n",
    "        result = {\"status\": \"error\", \"error_message\": \"Factorial is not defined for negative numbers.\"}\n",
    "        print(f\"   OUTPUT: {result}\")\n",
    "        return result\n",
    "    \n",
    "    if n > 170:\n",
    "        result = {\"status\": \"error\", \"error_message\": \"Number too large. Factorial computation limited to n <= 170.\"}\n",
    "        print(f\"   OUTPUT: {result}\")\n",
    "        return result\n",
    "    \n",
    "    try:\n",
    "        factorial_result = 1\n",
    "        for i in range(2, n + 1):\n",
    "            factorial_result *= i\n",
    "        \n",
    "        result = {\"status\": \"success\", \"result\": f\"The factorial of {n} is {factorial_result}\"}\n",
    "        print(f\"   OUTPUT: {result}\")\n",
    "        return result\n",
    "    except Exception as e:\n",
    "        result = {\"status\": \"error\", \"error_message\": f\"Error computing factorial: {str(e)}\"}\n",
    "        print(f\"   OUTPUT: {result}\")\n",
    "        return result\n",
    "\n",
    "def compute_exponential(base: float, exponent: float) -> dict:\n",
    "    \"\"\"Calculates base raised to the power of exponent.\n",
    "    \n",
    "    Args:\n",
    "        base (float): The base number\n",
    "        exponent (float): The exponent\n",
    "        \n",
    "    Returns:\n",
    "        dict: Computation status and result\n",
    "    \"\"\"\n",
    "    print(f\"ðŸ”§ TOOL CALLED: compute_exponential\")\n",
    "    print(f\"   INPUT: base = {base}, exponent = {exponent}\")\n",
    "    \n",
    "    try:\n",
    "        result_value = base ** exponent\n",
    "        \n",
    "        if abs(result_value) > 1e308:\n",
    "            result = {\"status\": \"error\", \"error_message\": \"Result too large to compute.\"}\n",
    "            print(f\"   OUTPUT: {result}\")\n",
    "            return result\n",
    "        \n",
    "        result = {\"status\": \"success\", \"result\": f\"{base} raised to the power of {exponent} is {result_value}\"}\n",
    "        print(f\"   OUTPUT: {result}\")\n",
    "        return result\n",
    "    except Exception as e:\n",
    "        result = {\"status\": \"error\", \"error_message\": f\"Error computing exponential: {str(e)}\"}\n",
    "        print(f\"   OUTPUT: {result}\")\n",
    "        return result\n",
    "\n",
    "def compute_fibonacci(n: int) -> dict:\n",
    "    \"\"\"Calculates the nth Fibonacci number (0-indexed).\n",
    "    \n",
    "    Args:\n",
    "        n (int): The position in the Fibonacci sequence (0-indexed)\n",
    "        \n",
    "    Returns:\n",
    "        dict: Computation status and result\n",
    "    \"\"\"\n",
    "    print(f\"ðŸ”§ TOOL CALLED: compute_fibonacci\")\n",
    "    print(f\"   INPUT: n = {n}\")\n",
    "    \n",
    "    if n < 0:\n",
    "        result = {\"status\": \"error\", \"error_message\": \"Fibonacci is not defined for negative positions.\"}\n",
    "        print(f\"   OUTPUT: {result}\")\n",
    "        return result\n",
    "    \n",
    "    if n > 1000:\n",
    "        result = {\"status\": \"error\", \"error_message\": \"Position too large. Fibonacci computation limited to n <= 1000.\"}\n",
    "        print(f\"   OUTPUT: {result}\")\n",
    "        return result\n",
    "    \n",
    "    try:\n",
    "        if n == 0:\n",
    "            fib_result = 0\n",
    "        elif n == 1:\n",
    "            fib_result = 1\n",
    "        else:\n",
    "            a, b = 0, 1\n",
    "            for _ in range(2, n + 1):\n",
    "                a, b = b, a + b\n",
    "            fib_result = b\n",
    "        \n",
    "        result = {\"status\": \"success\", \"result\": f\"The {n}th Fibonacci number is {fib_result}\"}\n",
    "        print(f\"   OUTPUT: {result}\")\n",
    "        return result\n",
    "    except Exception as e:\n",
    "        result = {\"status\": \"error\", \"error_message\": f\"Error computing Fibonacci: {str(e)}\"}\n",
    "        print(f\"   OUTPUT: {result}\")\n",
    "        return result\n",
    "\n",
    "print(\"âœ“ Mathematical tools defined successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "753e1f35-2c1b-40a3-9921-387b3c1ce009",
   "metadata": {},
   "source": [
    "## System Prompt and Tool Binding\n",
    "\n",
    "We define now the system prompt that will be used by the LLM.\n",
    "We also define a **Tool Dictionary**: Maps tool names to actual functions that will be helpful for manual execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5dafd36b-184c-47b8-be3a-893f9b9cbab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "math_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"\"\"You are a numeric computation specialist. \n",
    "You can calculate factorial, exponential (power), and Fibonacci numbers. \n",
    "When the user asks for computations, use the appropriate tool:\n",
    "- For factorial, use `compute_factorial`\n",
    "- For exponential (power), use `compute_exponential`\n",
    "- For Fibonacci, use `compute_fibonacci`\n",
    "\"\"\"),\n",
    "(\"user\", \"{query}\")\n",
    "])\n",
    "\n",
    "available_tools = {\n",
    "    \"compute_factorial\": compute_factorial,\n",
    "    \"compute_exponential\": compute_exponential,\n",
    "    \"compute_fibonacci\": compute_fibonacci\n",
    "}\n",
    "\n",
    "math_llm = ChatOpenAI(model=\"gpt-5-mini\").bind_tools(available_tools.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30e91f34-69a2-4558-bf0e-88be56cee78b",
   "metadata": {},
   "source": [
    "## LLM Invocation (First Call)\n",
    "\n",
    "Now we'll invoke the LLM with a query that requires tool usage.  \n",
    "\n",
    "\n",
    "The **Expected Behavior** if the following:\n",
    "- `response.content` will be empty (or minimal)\n",
    "- `response.tool_calls` will contain the tool call request(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c55bbf44-5048-4e50-9abb-7a0a59719154",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 88, 'prompt_tokens': 291, 'total_tokens': 379, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 64, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-5-mini-2025-08-07', 'system_fingerprint': None, 'id': 'chatcmpl-CjS2SBjkXoIiGysBG4LM6dY2hbshU', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None} id='lc_run--fce03c3b-aeb6-40c3-ac9a-0494ffc77d63-0' tool_calls=[{'name': 'compute_fibonacci', 'args': {'n': 8}, 'id': 'call_eqx44drrcbtZSihUOYxq7HDy', 'type': 'tool_call'}] usage_metadata={'input_tokens': 291, 'output_tokens': 88, 'total_tokens': 379, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 64}}\n"
     ]
    }
   ],
   "source": [
    "query = \"Tell me the value of fibonacci of 8\"\n",
    "\n",
    "messages = math_prompt.invoke({\"query\": query})\n",
    "response = math_llm.invoke(messages)\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e55317b6-03a5-47e7-b791-fb7567f50c25",
   "metadata": {},
   "source": [
    "### Response Analysis\n",
    "In the response you should have something like this where the content is empty but the llm ask you to call a tool\n",
    "\n",
    "<pre><span>AIMessage</span>(\n",
    "  <span>content</span>=<span class=\"string-value\">''</span>,\n",
    "  ...............\n",
    "  <div class=\"highlight-tool-calls\">\n",
    "  <b>tool_calls:</b>\n",
    "  [\n",
    "    {\n",
    "      '<span class=\"key\">name</span>': <span class=\"string-value\">'compute_fibonacci'</span>,\n",
    "      '<span class=\"key\">args</span>': {'<span class=\"key\">n</span>': <span class=\"number-value\">8</span>},\n",
    "      '<span class=\"key\">id</span>': <span class=\"string-value\">'call_XXXXXXXXXXXXXXXXX'</span>\n",
    "    }\n",
    "  ]\n",
    "  </div>\n",
    "  ..............\n",
    ")</pre>\n",
    "\n",
    "\n",
    "**Key Observations:**\n",
    "- **content = ''**: LLM hasn't provided a final answer yet so the content is empty\n",
    "- **tool_calls**: List of tools the LLM wants to execute\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2104404-3375-42c6-9250-c809ab108187",
   "metadata": {},
   "source": [
    "## Execute Tool Calls Manually\n",
    "\n",
    "Now we manually execute the tools that the LLM requested.\n",
    "\n",
    "**The Manual Process:**\n",
    "1. Loop through each tool call in `response.tool_calls`\n",
    "2. Extract the tool name and arguments\n",
    "3. Look up the actual function from our `available_tools` dictionary\n",
    "4. Execute the function with the provided arguments\n",
    "5. Collect the results\n",
    "\n",
    "**Why Manual Execution?**\n",
    "- In production libraries, this is automatic\n",
    "- Doing it manually helps you understand the flow\n",
    "- Allows custom error handling and logging\n",
    "- Enables tool execution optimization (parallel execution, caching, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9edac8cb-6d97-441b-96e4-3b195fdc42b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   EXECUTING: compute_fibonacci with args {'n': 8}\n",
      "ðŸ”§ TOOL CALLED: compute_fibonacci\n",
      "   INPUT: n = 8\n",
      "   OUTPUT: {'status': 'success', 'result': 'The 8th Fibonacci number is 21'}\n"
     ]
    }
   ],
   "source": [
    "tool_results = []\n",
    "\n",
    "for tool_call in response.tool_calls:\n",
    "    tool_name = tool_call[\"name\"]\n",
    "    tool_args = tool_call[\"args\"]\n",
    "    \n",
    "    print(f\"   EXECUTING: {tool_name} with args {tool_args}\")\n",
    "    \n",
    "    # Call the actual function\n",
    "    tool_function = available_tools[tool_name]\n",
    "    tool_output = tool_function(**tool_args)\n",
    "    \n",
    "    tool_results.append(tool_output) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5148c2a6-df64-45cc-81ce-8088054fecbd",
   "metadata": {},
   "source": [
    "### Ouput analysis\n",
    "\n",
    "You should have an output like the following:\n",
    "\n",
    "<pre>\n",
    " <b>OUTPUT:</b> {'status': 'success', 'result': 'The 8th Fibonacci number is 21'}\n",
    "</pre>\n",
    "We have manually performed what libraries typically handle automatically: tool invocation and iteration. In this example, iteration is not applied, but itâ€™s important to note that you could iterate to generate the final output.  \n",
    "For demonstration purposes, in the example, we will perform just two iterations. Instead of calling tools multiple times, we make a single tool call, pass the result back to the LLM, and continue the process.\n",
    "\n",
    "The iteration is a loop that executes until a stop condition is reached. A stop condition could be:\n",
    "- When `response.content` is not empty and `response.tool_calls` is empty, or\n",
    "- When a maximum number of iterations has been reached.\n",
    "Including a maximum iteration limit is essential, since an LLM may otherwise fall into infinite loops. Most libraries enforce such a limit by default to ensure safe and predictable execution.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8871debc-b036-4cbc-825e-dc9a10a9d6d0",
   "metadata": {},
   "source": [
    "## Second Iteration: Generate Final Response\n",
    "\n",
    "After generating the initial response, we should iterate once more to obtain the final response.  \n",
    "In this case, the iteration should produces a nonâ€‘empty `response.content` so the stop condition is reached and the result can be returned to the client."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e5575857-c887-4ee5-9727-35eca4267dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages_with_results = [\n",
    "    messages.messages[0],  # system message\n",
    "    messages.messages[1],  # user query\n",
    "    response,  # LLM's tool call request\n",
    "    {\"role\": \"tool\", \"content\": str(tool_results), \"tool_call_id\": response.tool_calls[0][\"id\"]}\n",
    "]\n",
    "\n",
    "# Get final answer from LLM\n",
    "final_response = math_llm.invoke(messages_with_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7ba246a7-cf4f-42aa-a713-b4c8897b1e34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final response is: The 8th Fibonacci number (0-indexed) is 21.\n"
     ]
    }
   ],
   "source": [
    "if final_response.content:\n",
    "    print(f\"Final response is: {final_response.content}\")\n",
    "else:\n",
    "    print(\"Strange result at this point the model should returns the answer, without asking other iterations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2c115b9-97bd-43d6-b868-6607d8a5591a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
